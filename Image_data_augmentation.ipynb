{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic Data Augmentation on Image Dataset\n",
    "\n",
    "This notebook demonstrates **Mosaic Data Augmentation**, a technique used to create new training images by combining four randomly selected images into one mosaic image. This augmentation strategy helps introduce varied backgrounds and complex object arrangements, enhancing the robustness of object detection models.\n",
    "\n",
    "## Overview of the Process\n",
    "1. **Select and Load Images**: Four images are randomly chosen from the input folder.\n",
    "2. **Calculate Image Density**: The image with the highest density of annotated objects (relative to its area) is identified. This \"densest\" image will occupy the largest area in the final mosaic.\n",
    "3. **Create Mosaic Image**:\n",
    "    - An empty canvas of 3000x3000 pixels is initialized.\n",
    "    - A random center point is selected to divide the canvas into four quadrants.\n",
    "    - The densest image is placed in the largest quadrant, while the other three images fill the remaining quadrants.\n",
    "4. **Save the Mosaic Image**: Each resulting mosaic image is saved to the specified output folder.\n",
    "\n",
    "## Key Functions\n",
    "- **calculate_density**: Computes the density of objects in each image based on annotations.\n",
    "- **crop_center**: Crops the central region of an image for better placement within the mosaic.\n",
    "- **mosaic_augmentation**: Combines the four images into a single mosaic, following the layout strategy described above.\n",
    "\n",
    "This process provides a richer dataset by blending parts of different images, simulating more complex scenes for improved model training.\n",
    "\n",
    "---\n",
    "\n",
    "After this description, proceed to the code cells below to run the Mosaic Data Augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def calculate_density(images, annotations_len):\n",
    "    '''\n",
    "    Calculate the density of an image\n",
    "    input:\n",
    "    images: list of images\n",
    "    annotations_len: list of annotations lengths    \n",
    "    output:     \n",
    "    max_density_index: index of the image with the highest density\n",
    "    '''\n",
    "    densities = [annotations_len[i] / (images[i].shape[0] * images[i].shape[1]) for i in range(len(images))]\n",
    "    max_density_index=np.argmax(densities)\n",
    "    return max_density_index\n",
    "\n",
    "\n",
    "def crop_center(image, target_height, target_width):\n",
    "    '''\n",
    "    crop the center of the image to the target size\n",
    "    input:\n",
    "    image: image\n",
    "    target_height: target height \n",
    "    target_width: target width\n",
    "    output: cropped image   \n",
    "\n",
    "    '''\n",
    "    h, w = image.shape[:2]\n",
    "    start_x = (w - target_width) // 2\n",
    "    start_y = (h - target_height) // 2\n",
    "    return image[start_y:start_y + target_height, start_x:start_x + target_width]\n",
    "def read_annotations(annotations_path):\n",
    "    '''\n",
    "    read annotations from the file\n",
    "    input:\n",
    "    annotations_path: path of the annotations file\n",
    "    output: \n",
    "    len(lines): number of lines in the file(objects in the image)\n",
    "    '''\n",
    "    with open(annotations_path, 'r') as file:\n",
    "        lines = file.readlines()[2:]\n",
    "        # Skip the first two lines\n",
    "    return len(lines)\n",
    "\n",
    "def mosaic_augmentation(images, max_density_index,output_folder_annotation,counter):\n",
    "    '''\n",
    "    make mosaic augmentation\n",
    "    input:\n",
    "    images: list of images\n",
    "    max_density_index: index of the image with the highest density\n",
    "    output_folder_annotation: path of the output folder\n",
    "    counter: counter\n",
    "    output: \n",
    "    mosaic_img: mosaic image\n",
    "    '''\n",
    "    mosaic_img = np.zeros((3000, 3000, 3), dtype=np.uint8) #make empty mosaic image with size 3000x3000\n",
    "    #claculate random point of image\n",
    "    center_x = random.randint(300, 2700) #claculate x coordinates of random point\n",
    "\n",
    "    center_y = random.randint(300, 2700) #claculate y coordinates of random point\n",
    "    # calculate 4 quarters of the image\n",
    "    quarters = [\n",
    "        (center_x * center_y, (0, center_y, 0, center_x)),  # top-left\n",
    "        ((3000 - center_x) * center_y, (0, center_y, center_x, 3000)),  # top-right\n",
    "        (center_x * (3000 - center_y), (center_y, 3000, 0, center_x)),  # bottom-left\n",
    "        ((3000 - center_x) * (3000 - center_y), (center_y, 3000, center_x, 3000))  # bottom-right\n",
    "    ]\n",
    "    \n",
    "    larger_quarter = max(quarters, key=lambda q: q[0])[1]\n",
    "    mosaic_img[larger_quarter[0]:larger_quarter[1], larger_quarter[2]:larger_quarter[3]] = cv2.resize(\n",
    "        images[max_density_index],\n",
    "        (larger_quarter[3] - larger_quarter[2], larger_quarter[1] - larger_quarter[0])\n",
    "    )\n",
    "\n",
    "   \n",
    "\n",
    "    remaining_images = [images[i] for i in range(4) if i != max_density_index]\n",
    "\n",
    "    # Calculate the positions of the other quarters if larger quarter is top-left\n",
    "    if larger_quarter == quarters[0][1]:  # top-left\n",
    "        positions = [\n",
    "            (0, center_y, center_x, 3000),  # top-right\n",
    "            (center_y, 3000, 0, center_x),   # bottom-left\n",
    "            (center_y,3000,center_x,3000)\n",
    "        ]\n",
    "      \n",
    "\n",
    "    # Calculate the positions of the other quarters if larger quarter is top-right\n",
    "\n",
    "    elif larger_quarter == quarters[1][1]:  # top-right\n",
    "        positions = [\n",
    "            (0, center_y, 0, center_x),      # top-left\n",
    "            (center_y, 3000, center_x, 3000),#bottom_right\n",
    "            (center_y, 3000, 0, center_x)\n",
    "              # bottom-right\n",
    "        ]\n",
    "   \n",
    "    # Calculate the positions of the other quarters if larger quarter is bottom-left\n",
    "    elif larger_quarter == quarters[2][1]:  # bottom-left\n",
    "        positions = [\n",
    "            (0, center_y, center_x, 3000),    # top-right\n",
    "            (0, center_y, 0, center_x),#top_left\n",
    "            (center_y,3000,center_x,3000)\n",
    "                              \n",
    "        ]\n",
    "    # Calculate the positions of the other quarters if larger quarter is bottom-right\n",
    "    else:  # bottom-right\n",
    "        positions = [\n",
    "            (0, center_y, 0, center_x),        # top-left\n",
    "            (center_y, 3000, 0, center_x),      # bottom-left\n",
    "            (0,center_y,center_x,3000)\n",
    "        ]\n",
    "   \n",
    "# Crop the images and paste them into the mosaic image\n",
    "    for img, pos in zip(remaining_images, positions):\n",
    "        mosaic_img[pos[0]:pos[1], pos[2]:pos[3]] = crop_center(img, pos[1] - pos[0], pos[3] - pos[2])\n",
    "\n",
    "    return mosaic_img\n",
    "\n",
    "\n",
    "# files path\n",
    "image_folder = 'path/input_image'\n",
    "output_folder = 'path/output_image'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "counter = 0\n",
    "while counter < 5:\n",
    "    image_paths = random.sample([os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')], 4)\n",
    "    images = [cv2.imread(img_path) for img_path in image_paths]\n",
    "    annotations_len = [read_annotations(ann_path) for ann_path in annotation_paths]\n",
    "\n",
    "# if all image load well\n",
    "    if not all(isinstance(img, np.ndarray) for img in images):\n",
    "        continue\n",
    "    max_density = calculate_density(images,annotations_len)\n",
    "    try:\n",
    "        mosaic_image = mosaic_augmentation(images, max_density,output_folder_annotation,counter)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    output_path = os.path.join(output_folder, f'mosaic_result_{counter}.jpg')\n",
    "    cv2.imwrite(output_path, mosaic_image)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutout Data Augmentation on DOTA Dataset\n",
    "\n",
    "This notebook demonstrates **Cutout Data Augmentation**, a technique for randomly obscuring parts of images by applying square cutouts. This process aids in making object detection models more robust by teaching them to recognize objects even when parts of the scene are hidden or missing.\n",
    "\n",
    "## Overview of the Process\n",
    "1. **Class Mapping Setup**: Defines the mapping between class names (e.g., \"plane\", \"ship\") and class IDs used in the annotations.\n",
    "2. **Image and Label Loading**: The `load_image_and_labels` function loads an image and its corresponding labels (coordinates and class IDs) from text files.\n",
    "3. **Applying Cutouts**:\n",
    "    - The `cutout` function applies a random square cutout on the image. Any objects (annotations) that overlap with the cutout area are removed from the final labels.\n",
    "    - The size and number of cutout regions can be specified; here, a single cutout region of 312x312 pixels is applied.\n",
    "4. **Drawing Annotations**: The `draw_annotations` function overlays the bounding polygons and class labels onto the image for both the original and cutout-augmented images, enabling a visual comparison.\n",
    "5. **Saving the Augmented Data**:\n",
    "    - The modified image, updated labels, and annotated images are saved to specified folders for later review and training.\n",
    "\n",
    "## Key Functions\n",
    "- **load_image_and_labels**: Loads the image and associated annotations, mapping each class name to its class ID.\n",
    "- **cutout**: Applies random cutouts to the image and removes annotations that overlap with the cutout region.\n",
    "- **draw_annotations**: Draws bounding polygons and class labels on the image.\n",
    "\n",
    "This approach is beneficial for datasets with varied object types and placements, as it introduces challenges that strengthen model performance in real-world scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "You can now proceed to run the code cells to see the cutout augmentation in action on the DOTA dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Mapping for class labels\n",
    "class_mapping = {\n",
    "    'plane': 0,\n",
    "    'ship': 1,\n",
    "    'storage-tank': 2,\n",
    "    'baseball-diamond': 3,\n",
    "    'tennis-court': 4,\n",
    "    'basketball-court': 5,\n",
    "    'ground-track-field': 6,\n",
    "    'harbor': 7,\n",
    "    'bridge': 8,\n",
    "    'large-vehicle': 9,\n",
    "    'small-vehicle': 10,\n",
    "    'helicopter': 11,\n",
    "    'roundabout': 12,\n",
    "    'soccer-ball-field': 13,\n",
    "    'swimming-pool': 14,\n",
    "    'container-crane': 15\n",
    "}\n",
    "\n",
    "# Invert class mapping for easy access\n",
    "class_names = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "def load_image_and_labels(image_path, label_path):\n",
    "    '''\n",
    "    Load image and labels from a text file\n",
    "    input: image_path, label_path\n",
    "    output: image, labels\n",
    "\n",
    "    '''\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image at {image_path}\") # Raise an exception if the image could not be loaded\n",
    "    \n",
    "    labels = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        content = file.readlines()\n",
    "    \n",
    "    for line in content[1:]:  # Skip the first and second lines\n",
    "        if line.startswith(\"imagesource\") or line.startswith(\"gsd\"):\n",
    "            continue\n",
    "        \n",
    "        parts = line.strip().split()\n",
    "        coords = list(map(float, parts[:-2]))\n",
    "        class_name = parts[-2]\n",
    "        class_id = class_mapping.get(class_name)\n",
    "        \n",
    "        if class_id is None:\n",
    "            raise ValueError(f\"Class '{class_name}' not found in the class mapping.\")\n",
    "        \n",
    "        labels.append(coords + [class_id])\n",
    "\n",
    "    return image, np.array(labels)\n",
    "\n",
    "def cutout(image, labels, n_holes=1, length=512):\n",
    "    '''\n",
    "    make a cutout on the image\n",
    "    input: image, labels, n_holes, length\n",
    "    output: image, labels, deleted_annotations\n",
    "    \n",
    "    '''\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    new_labels = []\n",
    "    deleted_annotations = []  # List to keep track of deleted annotations\n",
    "\n",
    "    for _ in range(n_holes):\n",
    "        # Randomly select the position to cut out\n",
    "        y = np.random.randint(0, h)\n",
    "        x = np.random.randint(0, w)\n",
    "\n",
    "        # Calculate the square coordinates\n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "\n",
    "        # Apply cutout\n",
    "        image[y1:y2, x1:x2] = 0\n",
    "        \n",
    "        # Check for overlaps with annotations and remove them\n",
    "        for label in labels:\n",
    "            coords = label[:-1]  # Get coordinates of the annotation\n",
    "            if (\n",
    "                (coords[0] < x2 and coords[2] > x1 and coords[1] < y2 and coords[5] > y1)\n",
    "            ):  # Check if there's an overlap\n",
    "                deleted_annotations.append(label)  # Store deleted annotation\n",
    "                continue  # Skip this annotation if it overlaps\n",
    "            new_labels.append(label)  # Keep the annotation if it doesn't overlap\n",
    "    \n",
    "    return image, np.array(new_labels), deleted_annotations\n",
    "\n",
    "\n",
    "def draw_annotations(image, labels, color=(0, 255, 0), thickness=2):\n",
    "    '''\n",
    "    draw annotations on the image\n",
    "    input: image, labels, color, thickness\n",
    "    output: image\n",
    "    '''\n",
    "    for label in labels:\n",
    "        coords = np.array(label[:-1], dtype=np.int32).reshape((-1, 2))\n",
    "        class_id = int(label[-1])\n",
    "        class_name = class_names[class_id]\n",
    "        cv2.polylines(image, [coords], isClosed=True, color=color, thickness=thickness)\n",
    "        cv2.putText(image, class_name, (coords[0][0], coords[0][1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "# Dataset paths\n",
    "database_folder = 'path/train/image'\n",
    "label_folder = 'path/train/annotation'\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(database_folder) if f.endswith('.png')]\n",
    "\n",
    "# Number of images to generate\n",
    "num_images_to_generate = 100\n",
    "\n",
    "for i in range(num_images_to_generate):\n",
    "    random_file = random.choice(image_files)\n",
    "\n",
    "    # Load image and labels\n",
    "    image, labels = load_image_and_labels(\n",
    "        os.path.join(database_folder, random_file), \n",
    "        os.path.join(label_folder, random_file.replace('.png', '.txt'))\n",
    "    )\n",
    "\n",
    "    # Draw annotations on the original image for comparison\n",
    "    original_annotated_image = image.copy()\n",
    "    draw_annotations(original_annotated_image, labels)\n",
    "\n",
    "    # Apply cutout\n",
    "    cutout_image, new_labels, deleted_annotations = cutout(image.copy(), labels, n_holes=1, length=312)\n",
    "\n",
    "    # Draw annotations on cutout image\n",
    "    annotated_image = cutout_image.copy()\n",
    "    draw_annotations(annotated_image, new_labels)\n",
    "\n",
    "    # Save the cutout image and labels\n",
    "    output_image_path = f'path/save/image/cutoutpic-3{i + 1}.jpg'\n",
    "    output_labels_path = f'path/save/label/cutoutpic-3{i + 1}.txt'\n",
    "    output_annotated_image_path = f'path/save/image_annotate/cutoutpic-3{i + 1}.jpg'\n",
    "    \n",
    " \n",
    "\n",
    "    # Save cutout image\n",
    "    cv2.imwrite(output_image_path, cutout_image)\n",
    "\n",
    "    # Save new annotations\n",
    "    np.savetxt(output_labels_path, new_labels, fmt='%.2f', delimiter=' ', header='x1 y1 x2 y2 x3 y3 x4 y4 class', comments='')\n",
    "\n",
    "    # Save annotated cutout image\n",
    "    cv2.imwrite(output_annotated_image_path, annotated_image)\n",
    "\n",
    "    # # Save original annotated image\n",
    "    # cv2.imwrite(original_annotated_image_path, original_annotated_image)\n",
    "\n",
    "\n",
    "    print(f\"Cutout image saved at: {output_image_path}\")\n",
    "    print(f\"Cutout labels saved at: {output_labels_path}\")\n",
    "    print(f\"Annotated cutout image saved at: {output_annotated_image_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
